package top.yumbo.ai.omni.storage.file;

import lombok.extern.slf4j.Slf4j;
import top.yumbo.ai.omni.storage.api.model.*;
import top.yumbo.ai.omni.storage.api.DocumentStorageService;

import java.io.*;
import java.nio.file.*;
import java.util.*;
import java.util.stream.Collectors;

/**
 * File å­˜å‚¨å®ç° - æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿå­˜å‚¨ï¼ˆç”¨äºå¼€å‘å’Œæµ‹è¯•ï¼‰
 * (File Storage Implementation - Local file system storage for development and testing)
 *
 * <p>
 * ç‰¹ç‚¹ (Features):
 * - æœ¬åœ°æ–‡ä»¶å­˜å‚¨ï¼Œæ— éœ€å¤–éƒ¨ä¾èµ–
 * - å¿«é€Ÿå¯åŠ¨ï¼Œé€‚åˆå¼€å‘æµ‹è¯•
 * - ç›®å½•ç»“æ„æ¸…æ™°
 * - æ”¯æŒå¤§æ–‡ä»¶
 * </p>
 *
 * @author OmniAgent Team
 * @version 1.0.0 - File Starter å®ç°
 * @since 1.0.0
 */
@Slf4j
public class FileDocumentStorage implements DocumentStorageService {

    private final Path basePath;
    private final Path chunksPath;
    private final Path imagesPath;
    private final Path pplPath;
    private final Path optimizationPath;
    private final Path documentsPath;
    private final Path extractedPath;  // â­ æ–°å¢ï¼šæå–æ–‡æœ¬è·¯å¾„

    public FileDocumentStorage(String baseDirectory) {
        this.basePath = Paths.get(baseDirectory);
        this.chunksPath = basePath.resolve("chunks");
        this.imagesPath = basePath.resolve("images");
        this.pplPath = basePath.resolve("ppl");
        this.optimizationPath = basePath.resolve("optimization");
        this.documentsPath = basePath.resolve("documents");
        this.extractedPath = basePath.resolve("extracted");  // â­ æ–°å¢

        initDirectories();
        log.info("FileDocumentStorage initialized at: {}", basePath.toAbsolutePath());
    }

    private void initDirectories() {
        try {
            Files.createDirectories(chunksPath);
            Files.createDirectories(imagesPath);
            Files.createDirectories(pplPath);
            Files.createDirectories(optimizationPath);
            Files.createDirectories(documentsPath);
            Files.createDirectories(extractedPath);  // â­ æ–°å¢
        } catch (IOException e) {
            log.error("Failed to create storage directories", e);
            throw new RuntimeException("Failed to initialize file storage", e);
        }
    }

    // ========== Raw Document Storage ==========

    @Override
    public String saveDocument(String documentId, String filename, byte[] fileData) {
        try {
            // æ ¹æ®æ–‡ä»¶åå‰ç¼€åˆ¤æ–­ä¿å­˜è·¯å¾„ â­
            Path targetPath;
            String actualFilename;

            if (filename.startsWith("extracted/")) {
                // æå–ç»“æœä¿å­˜åˆ° extracted/ ç›®å½•
                actualFilename = filename.substring("extracted/".length());
                targetPath = extractedPath;
            } else {
                // é»˜è®¤ä¿å­˜åˆ° documents/ ç›®å½•
                actualFilename = filename;
                targetPath = documentsPath;
            }

            // ä½¿ç”¨åŸæ–‡ä»¶åç›´æ¥ä¿å­˜ï¼ˆä¿ç•™ç›¸å¯¹è·¯å¾„ä¸­çš„ç›®å½•ç»“æ„ï¼‰
            // ä¾‹å¦‚: filename = "è®¾è®¡å›¾/æ¶æ„å›¾.pptx"
            //      ä¿å­˜ä¸º: documents/è®¾è®¡å›¾/æ¶æ„å›¾.pptx
            Path documentFile = targetPath.resolve(actualFilename);

            // ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
            Path parentDir = documentFile.getParent();
            if (parentDir != null) {
                Files.createDirectories(parentDir);
            }

            Files.write(documentFile, fileData);

            log.debug("Saved document: {} to {}", actualFilename, targetPath.getFileName());
            return documentId;
        } catch (IOException e) {
            log.error("Failed to save document: {}", filename, e);
            return null;
        }
    }

    @Override
    public Optional<byte[]> getDocument(String documentId) {
        try {
            // åˆ¤æ–­æ˜¯ä»å“ªä¸ªç›®å½•è¯»å– â­
            Path targetPath;
            String actualFilename;

            if (documentId.startsWith("extracted/")) {
                // ä» extracted/ ç›®å½•è¯»å–
                actualFilename = documentId.substring("extracted/".length());
                targetPath = extractedPath;
            } else {
                // ä» documents/ ç›®å½•è¯»å–
                actualFilename = documentId;
                targetPath = documentsPath;
            }

            // ç›´æ¥è¯»å–æŒ‡å®šæ–‡ä»¶
            Path documentFile = targetPath.resolve(actualFilename);
            if (Files.exists(documentFile)) {
                byte[] data = Files.readAllBytes(documentFile);
                log.debug("Read document: {} from {}", actualFilename, targetPath.getFileName());
                return Optional.of(data);
            }

            // å¦‚æœæŒ‡å®šè·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•éå†æŸ¥æ‰¾ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
            // â­ å…ˆæ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œé¿å… NoSuchFileException
            if (!Files.exists(targetPath)) {
                log.debug("Target directory does not exist: {}", targetPath);
                return Optional.empty();
            }

            Path[] files = Files.walk(targetPath, 10)
                    .filter(Files::isRegularFile)
                    .filter(p -> p.getFileName().toString().contains(actualFilename))
                    .toArray(Path[]::new);

            if (files.length > 0) {
                byte[] data = Files.readAllBytes(files[0]);
                log.debug("Found document by search: {}", files[0]);
                return Optional.of(data);
            }

            log.debug("Document not found: {}", documentId);
            return Optional.empty();
        } catch (IOException e) {
            log.error("Failed to get document: {}", documentId, e);
            return Optional.empty();
        }
    }

    @Override
    public void deleteDocument(String documentId) {
        try {
            // documentId å°±æ˜¯åŸå§‹æ–‡ä»¶å
            Path documentFile = documentsPath.resolve(documentId);
            if (Files.exists(documentFile)) {
                Files.delete(documentFile);
                log.debug("Deleted document file: {}", documentFile);
            } else {
                log.warn("Document file not found: {}", documentFile);
            }

            // æ¸…ç†ç›¸å…³çš„æ‰€æœ‰æ•°æ®ï¼ˆchunksã€imagesã€pplã€optimizationï¼‰â­
            cleanupDocument(documentId);

            log.info("Successfully deleted document and all related data: {}", documentId);
        } catch (IOException e) {
            log.error("Failed to delete document: {}", documentId, e);
        }
    }

    // ========== Extracted Text Storage â­ NEW ==========

    @Override
    public String saveExtractedText(String documentId, String text) {
        try {
            // ä½¿ç”¨ documentId.txt ä½œä¸ºæ–‡ä»¶å
            Path textFile = extractedPath.resolve(documentId + ".txt");

            // ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
            Path parentDir = textFile.getParent();
            if (parentDir != null) {
                Files.createDirectories(parentDir);
            }

            // ä¿å­˜æ–‡æœ¬å†…å®¹
            Files.writeString(textFile, text, java.nio.charset.StandardCharsets.UTF_8);

            log.debug("âœ… Saved extracted text: {}, length={}", documentId, text.length());
            return documentId;
        } catch (IOException e) {
            log.error("âŒ Failed to save extracted text: {}", documentId, e);
            return null;
        }
    }

    @Override
    public Optional<String> getExtractedText(String documentId) {
        try {
            Path textFile = extractedPath.resolve(documentId + ".txt");

            if (Files.exists(textFile)) {
                String text = Files.readString(textFile, java.nio.charset.StandardCharsets.UTF_8);
                log.debug("âœ… Retrieved extracted text: {}, length={}", documentId, text.length());
                return Optional.of(text);
            } else {
                log.debug("âš ï¸ Extracted text not found: {}", documentId);
                return Optional.empty();
            }
        } catch (IOException e) {
            log.error("âŒ Failed to get extracted text: {}", documentId, e);
            return Optional.empty();
        }
    }

    @Override
    public void deleteExtractedText(String documentId) {
        try {
            Path textFile = extractedPath.resolve(documentId + ".txt");

            if (Files.exists(textFile)) {
                Files.delete(textFile);
                log.debug("ğŸ—‘ï¸ Deleted extracted text: {}", documentId);
            } else {
                log.debug("âš ï¸ Extracted text not found: {}", documentId);
            }
        } catch (IOException e) {
            log.error("âŒ Failed to delete extracted text: {}", documentId, e);
        }
    }

    // ========== Chunk Storage ==========

    @Override
    public String saveChunk(String documentId, Chunk chunk) {
        try {
            // ä½¿ç”¨åŸå§‹æ–‡ä»¶åä½œä¸ºç›®å½•ï¼ˆä»chunkæˆ–documentIdè·å–ï¼‰
            // documentId åœ¨è°ƒç”¨æ—¶åº”è¯¥å·²ç»æ˜¯åŸå§‹æ–‡ä»¶å
            Path docChunkDir = chunksPath.resolve(documentId);
            Files.createDirectories(docChunkDir);

            // ä½¿ç”¨æœ‰æ„ä¹‰çš„æ–‡ä»¶åï¼šchunk_åºå·.md â­
            String chunkId = chunk.getId() != null ? chunk.getId() : UUID.randomUUID().toString();
            int sequence = chunk.getSequence();
            String chunkFilename = String.format("chunk_%03d.md", sequence);  // æ·»åŠ .mdåç¼€
            Path chunkFile = docChunkDir.resolve(chunkFilename);

            // ç›´æ¥ä¿å­˜åˆ†å—çš„æ–‡æœ¬å†…å®¹ï¼Œè€Œä¸æ˜¯åºåˆ—åŒ–å¯¹è±¡ â­
            Files.write(chunkFile, chunk.getContent().getBytes(java.nio.charset.StandardCharsets.UTF_8));

            // åŒæ—¶ä¿å­˜å…ƒæ•°æ®åˆ° JSON æ–‡ä»¶ï¼Œæ–¹ä¾¿æŸ¥è¯¢
            String metadataFilename = chunkFilename + ".meta";
            Path metadataFile = docChunkDir.resolve(metadataFilename);
            String metadataJson = buildChunkMetadataJson(chunk, chunkFilename);
            Files.write(metadataFile, metadataJson.getBytes(java.nio.charset.StandardCharsets.UTF_8));

            log.debug("Saved chunk: {} -> {}/{}", chunkId, documentId, chunkFilename);
            return chunkId;
        } catch (IOException e) {
            log.error("Failed to save chunk for document: {}", documentId, e);
            return null;
        }
    }

    /**
     * æ„å»ºåˆ†å—å…ƒæ•°æ® JSON
     */
    private String buildChunkMetadataJson(Chunk chunk, String filename) {
        StringBuilder json = new StringBuilder();
        json.append("{\n");
        json.append("  \"id\": \"").append(chunk.getId()).append("\",\n");
        json.append("  \"documentId\": \"").append(chunk.getDocumentId()).append("\",\n");
        json.append("  \"filename\": \"").append(filename).append("\",\n");
        json.append("  \"sequence\": ").append(chunk.getSequence()).append(",\n");
        if (chunk.getStartPosition() != null) {
            json.append("  \"startPosition\": ").append(chunk.getStartPosition()).append(",\n");
        }
        if (chunk.getEndPosition() != null) {
            json.append("  \"endPosition\": ").append(chunk.getEndPosition()).append(",\n");
        }
        json.append("  \"size\": ").append(chunk.getSize()).append(",\n");
        if (chunk.getMetadata() != null && !chunk.getMetadata().isEmpty()) {
            json.append("  \"metadata\": ").append(mapToJson(chunk.getMetadata())).append(",\n");
        }
        json.append("  \"createdAt\": ").append(chunk.getCreatedAt() != null ? chunk.getCreatedAt() : System.currentTimeMillis()).append("\n");
        json.append("}");
        return json.toString();
    }

    /**
     * å°† Map è½¬æ¢ä¸ºç®€å•çš„ JSON å­—ç¬¦ä¸²
     */
    private String mapToJson(Map<String, Object> map) {
        StringBuilder json = new StringBuilder();
        json.append("{");
        boolean first = true;
        for (Map.Entry<String, Object> entry : map.entrySet()) {
            if (!first) json.append(", ");
            json.append("\"").append(entry.getKey()).append("\": ");
            Object value = entry.getValue();
            if (value instanceof String) {
                json.append("\"").append(value).append("\"");
            } else if (value instanceof Number || value instanceof Boolean) {
                json.append(value);
            } else {
                json.append("\"").append(value).append("\"");
            }
            first = false;
        }
        json.append("}");
        return json.toString();
    }

    /**
     * ä» documentId æå–åŸæ–‡ä»¶å
     *
     * @deprecated ä¸å†ä½¿ç”¨ï¼Œä¿ç•™ç”¨äºå‘åå…¼å®¹
     * æ–°çš„è®¾è®¡ä¸­ documentId å°±æ˜¯åŸå§‹æ–‡ä»¶å
     */
    @Deprecated
    private String extractFilenameFromDocumentId(String documentId) {
        // doc_1766142807149_å€¡å¯¼èŠ‚çº¦ç”¨æ°´.pptx -> å€¡å¯¼èŠ‚çº¦ç”¨æ°´.pptx
        if (documentId.startsWith("doc_")) {
            int secondUnderscore = documentId.indexOf('_', 4);
            if (secondUnderscore > 0 && secondUnderscore < documentId.length() - 1) {
                return documentId.substring(secondUnderscore + 1);
            }
        }
        return documentId; // é™çº§ï¼šç›´æ¥ä½¿ç”¨
    }

    @Override
    public List<String> saveChunks(String documentId, List<Chunk> chunks) {
        List<String> chunkIds = new ArrayList<>();
        for (Chunk chunk : chunks) {
            String chunkId = saveChunk(documentId, chunk);
            if (chunkId != null) {
                chunkIds.add(chunkId);
            }
        }
        return chunkIds;
    }

    @Override
    public Optional<Chunk> getChunk(String chunkId) {
        try {
            // åœ¨æ‰€æœ‰æ–‡æ¡£çš„åˆ†å—ç›®å½•ä¸­æœç´¢å…ƒæ•°æ®æ–‡ä»¶
            List<Path> metadataFiles = Files.walk(chunksPath, 2)
                    .filter(Files::isRegularFile)
                    .filter(p -> p.getFileName().toString().endsWith(".meta"))
                    .collect(Collectors.toList());

            if (metadataFiles.isEmpty()) {
                return Optional.empty();
            }

            // æŸ¥æ‰¾åŒ¹é…çš„å…ƒæ•°æ®æ–‡ä»¶
            for (Path metadataFile : metadataFiles) {
                try {
                    String metadataJson = new String(Files.readAllBytes(metadataFile), java.nio.charset.StandardCharsets.UTF_8);
                    if (metadataJson.contains("\"id\": \"" + chunkId + "\"")) {
                        // æ‰¾åˆ°åŒ¹é…çš„å…ƒæ•°æ®ï¼Œè¯»å–åˆ†å—
                        String chunkFilename = metadataFile.getFileName().toString().replace(".meta", "");
                        Path chunkFile = metadataFile.getParent().resolve(chunkFilename);

                        if (Files.exists(chunkFile)) {
                            return Optional.of(loadChunkFromFiles(chunkFile, metadataFile));
                        }
                    }
                } catch (IOException e) {
                    log.error("Failed to read metadata file: {}", metadataFile, e);
                }
            }

            return Optional.empty();
        } catch (IOException e) {
            log.error("Failed to get chunk: {}", chunkId, e);
            return Optional.empty();
        }
    }

    @Override
    public List<Chunk> getChunksByDocument(String documentId) {
        try {
            Path docChunkDir = chunksPath.resolve(documentId);
            if (!Files.exists(docChunkDir)) {
                return new ArrayList<>();
            }

            return Files.list(docChunkDir)
                    .filter(Files::isRegularFile)
                    .filter(p -> !p.getFileName().toString().endsWith(".meta")) // åªå¤„ç†åˆ†å—æ–‡ä»¶
                    .filter(p -> p.getFileName().toString().startsWith("chunk_"))
                    .map(chunkFile -> {
                        try {
                            Path metadataFile = chunkFile.getParent().resolve(chunkFile.getFileName() + ".meta");
                            if (Files.exists(metadataFile)) {
                                return loadChunkFromFiles(chunkFile, metadataFile);
                            } else {
                                // å…¼å®¹æ—§æ ¼å¼ï¼šå°è¯•ååºåˆ—åŒ–
                                try (ObjectInputStream ois = new ObjectInputStream(new FileInputStream(chunkFile.toFile()))) {
                                    return (Chunk) ois.readObject();
                                } catch (Exception oldFormatEx) {
                                    log.warn("Cannot load chunk (old or new format): {}", chunkFile);
                                    return null;
                                }
                            }
                        } catch (IOException e) {
                            log.error("Failed to read chunk file: {}", chunkFile, e);
                            return null;
                        }
                    })
                    .filter(Objects::nonNull)
                    .collect(Collectors.toList());
        } catch (IOException e) {
            log.error("Failed to get chunks for document: {}", documentId, e);
            return new ArrayList<>();
        }
    }

    /**
     * ä»åˆ†å—æ–‡ä»¶å’Œå…ƒæ•°æ®æ–‡ä»¶åŠ è½½ Chunk å¯¹è±¡
     */
    private Chunk loadChunkFromFiles(Path chunkFile, Path metadataFile) throws IOException {
        // è¯»å–åˆ†å—æ–‡æœ¬å†…å®¹
        String content = new String(Files.readAllBytes(chunkFile), java.nio.charset.StandardCharsets.UTF_8);

        // è¯»å–å…ƒæ•°æ®
        String metadataJson = new String(Files.readAllBytes(metadataFile), java.nio.charset.StandardCharsets.UTF_8);

        // è§£æå…ƒæ•°æ®
        String id = extractJsonValue(metadataJson, "id");
        String documentId = extractJsonValue(metadataJson, "documentId");
        Integer sequence = extractJsonIntValue(metadataJson, "sequence");
        Integer startPosition = extractJsonIntValue(metadataJson, "startPosition");
        Integer endPosition = extractJsonIntValue(metadataJson, "endPosition");
        Long createdAt = extractJsonLongValue(metadataJson, "createdAt");

        return Chunk.builder()
                .id(id)
                .documentId(documentId)
                .content(content)
                .sequence(sequence != null ? sequence : 0)
                .startPosition(startPosition)
                .endPosition(endPosition)
                .createdAt(createdAt)
                .build();
    }

    /**
     * ä» JSON å­—ç¬¦ä¸²ä¸­æå– Long å€¼
     */
    private Long extractJsonLongValue(String json, String key) {
        String pattern = "\"" + key + "\": ";
        int start = json.indexOf(pattern);
        if (start == -1) return null;
        start += pattern.length();
        int end = json.indexOf(",", start);
        if (end == -1) {
            end = json.indexOf("\n", start);
        }
        if (end == -1) return null;
        try {
            return Long.parseLong(json.substring(start, end).trim());
        } catch (NumberFormatException e) {
            return null;
        }
    }

    @Override
    public void deleteChunk(String chunkId) {
        try {
            Files.walk(chunksPath, 2)
                    .filter(p -> p.toString().endsWith(chunkId + ".chunk"))
                    .forEach(p -> {
                        try {
                            Files.delete(p);
                            log.debug("Deleted chunk: {}", chunkId);
                        } catch (IOException e) {
                            log.error("Failed to delete chunk: {}", chunkId, e);
                        }
                    });
        } catch (IOException e) {
            log.error("Failed to delete chunk: {}", chunkId, e);
        }
    }

    @Override
    public void deleteChunksByDocument(String documentId) {
        try {
            Path docChunkDir = chunksPath.resolve(documentId);
            if (Files.exists(docChunkDir)) {
                Files.walk(docChunkDir)
                        .sorted(Comparator.reverseOrder())
                        .forEach(p -> {
                            try {
                                Files.delete(p);
                            } catch (IOException e) {
                                log.error("Failed to delete: {}", p, e);
                            }
                        });
                log.info("Deleted all chunks for document: {}", documentId);
            }
        } catch (IOException e) {
            log.error("Failed to delete chunks for document: {}", documentId, e);
        }
    }

    // ========== Image Storage ==========

    @Override
    public String saveImage(String documentId, Image image) {
        try {
            Path docImageDir = imagesPath.resolve(documentId);
            Files.createDirectories(docImageDir);

            // â­ å¼ºåˆ¶è¦æ±‚é¡µç ä¿¡æ¯
            Integer pageNum = image.getPageNumber();
            if (pageNum == null || pageNum <= 0) {
                throw new IllegalArgumentException(
                    String.format("Image must have valid pageNumber (got: %s, documentId: %s). " +
                                "All images must be assigned a page number.",
                                pageNum, documentId));
            }

            // ä» metadata ä¸­è·å–å›¾ç‰‡åºå·å’ŒåŸºç¡€æ–‡ä»¶å
            Integer imageIndex = null;
            String baseName = documentId;  // é»˜è®¤ä½¿ç”¨documentId
            if (image.getMetadata() != null) {
                if (image.getMetadata().containsKey("imageIndex")) {
                    imageIndex = ((Number) image.getMetadata().get("imageIndex")).intValue();
                }
                if (image.getMetadata().containsKey("baseName")) {
                    baseName = (String) image.getMetadata().get("baseName");
                }
            }

            String format = image.getFormat() != null ? image.getFormat() : "png";

            // â­ æ„å»ºç®€æ´çš„æ–‡ä»¶åï¼šp001_i000.pngï¼ˆé¡µç 3ä½ï¼Œå›¾ç‰‡åºå·3ä½ï¼‰
            // ä¸åŒ…å« baseNameï¼Œå› ä¸ºå·²ç»åœ¨æ–‡ä»¶å¤¹åä¸­äº†
            String imageFilename;
            if (imageIndex != null && imageIndex >= 0) {
                imageFilename = String.format("p%03d_i%03d.%s", pageNum, imageIndex, format);
            } else {
                // å¦‚æœæ²¡æœ‰å›¾ç‰‡åºå·ï¼Œåªæœ‰é¡µç ï¼šp001.png
                imageFilename = String.format("p%03d.%s", pageNum, format);
            }

            Path imageFile = docImageDir.resolve(imageFilename);

            // ä¿å­˜å›¾ç‰‡çš„äºŒè¿›åˆ¶æ•°æ®
            Files.write(imageFile, image.getData());

            // ä¿å­˜å…ƒæ•°æ®åˆ° JSON æ–‡ä»¶
            String metadataFilename = imageFilename + ".meta";
            Path metadataFile = docImageDir.resolve(metadataFilename);
            String metadataJson = buildImageMetadataJson(image, imageFilename);
            Files.write(metadataFile, metadataJson.getBytes(java.nio.charset.StandardCharsets.UTF_8));

            // â­ imageId ä¿æŒåŸæ ·ï¼ˆç”¨äºå…¨å±€å”¯ä¸€æ ‡è¯†ï¼‰ï¼šbaseName_p001_i000
            String imageId = String.format("%s_p%03d_i%03d", baseName, pageNum, imageIndex != null ? imageIndex : 0);

            log.debug("Saved image: {} -> {}/{}", imageId, documentId, imageFilename);
            return imageId;
        } catch (IOException e) {
            log.error("Failed to save image", e);
            return null;
        }
    }

    /**
     * æ„å»ºå›¾ç‰‡å…ƒæ•°æ® JSON
     */
    private String buildImageMetadataJson(Image image, String filename) {
        StringBuilder json = new StringBuilder();
        json.append("{\n");
        json.append("  \"id\": \"").append(image.getId()).append("\",\n");
        json.append("  \"documentId\": \"").append(image.getDocumentId()).append("\",\n");
        json.append("  \"filename\": \"").append(filename).append("\",\n");
        json.append("  \"format\": \"").append(image.getFormat()).append("\",\n");
        if (image.getWidth() != null) {
            json.append("  \"width\": ").append(image.getWidth()).append(",\n");
        }
        if (image.getHeight() != null) {
            json.append("  \"height\": ").append(image.getHeight()).append(",\n");
        }
        if (image.getPageNumber() != null) {
            json.append("  \"pageNumber\": ").append(image.getPageNumber()).append(",\n");
        }
        json.append("  \"size\": ").append(image.getSize()).append(",\n");

        // æ·»åŠ  metadata å­—æ®µï¼ˆåŒ…å«å›¾ç‰‡æè¿°ç­‰ä¿¡æ¯ï¼‰â­
        if (image.getMetadata() != null && !image.getMetadata().isEmpty()) {
            json.append("  \"metadata\": ").append(mapToJson(image.getMetadata())).append(",\n");
        }

        json.append("  \"createdAt\": ").append(System.currentTimeMillis()).append("\n");
        json.append("}");
        return json.toString();
    }

    @Override
    public Optional<Image> getImage(String imageId) {
        try {
            // åœ¨æ‰€æœ‰æ–‡æ¡£çš„å›¾ç‰‡ç›®å½•ä¸­æœç´¢å…ƒæ•°æ®æ–‡ä»¶
            List<Path> metadataFiles = Files.walk(imagesPath, 2)
                    .filter(Files::isRegularFile)
                    .filter(p -> p.getFileName().toString().endsWith(".meta"))
                    .toList();

            if (metadataFiles.isEmpty()) {
                return Optional.empty();
            }

            // æŸ¥æ‰¾åŒ¹é…çš„å…ƒæ•°æ®æ–‡ä»¶
            for (Path metadataFile : metadataFiles) {
                try {
                    String metadataJson = new String(Files.readAllBytes(metadataFile), java.nio.charset.StandardCharsets.UTF_8);
                    if (metadataJson.contains("\"id\": \"" + imageId + "\"")) {
                        // æ‰¾åˆ°åŒ¹é…çš„å…ƒæ•°æ®ï¼Œè¯»å–å›¾ç‰‡
                        String imageFilename = metadataFile.getFileName().toString().replace(".meta", "");
                        Path imageFile = metadataFile.getParent().resolve(imageFilename);

                        if (Files.exists(imageFile)) {
                            return Optional.of(loadImageFromFiles(imageFile, metadataFile));
                        }
                    }
                } catch (IOException e) {
                    log.error("Failed to read metadata file: {}", metadataFile, e);
                }
            }

            return Optional.empty();
        } catch (IOException e) {
            log.error("Failed to get image: {}", imageId, e);
            return Optional.empty();
        }
    }

    @Override
    public List<Image> getImagesByDocument(String documentId) {
        try {
            Path docImageDir = imagesPath.resolve(documentId);
            if (!Files.exists(docImageDir)) {
                return new ArrayList<>();
            }

            return Files.list(docImageDir)
                    .filter(Files::isRegularFile)
                    .filter(p -> !p.getFileName().toString().endsWith(".meta")) // åªå¤„ç†å›¾ç‰‡æ–‡ä»¶
                    .filter(p -> {
                        String name = p.getFileName().toString();
                        return name.startsWith("page_") || name.startsWith("image_");
                    })
                    .map(imageFile -> {
                        try {
                            Path metadataFile = imageFile.getParent().resolve(imageFile.getFileName() + ".meta");
                            if (Files.exists(metadataFile)) {
                                return loadImageFromFiles(imageFile, metadataFile);
                            } else {
                                // å…¼å®¹æ—§æ ¼å¼ï¼šå°è¯•ååºåˆ—åŒ–
                                try (ObjectInputStream ois = new ObjectInputStream(new FileInputStream(imageFile.toFile()))) {
                                    return (Image) ois.readObject();
                                } catch (Exception oldFormatEx) {
                                    log.warn("Cannot load image (old or new format): {}", imageFile);
                                    return null;
                                }
                            }
                        } catch (IOException e) {
                            log.error("Failed to read image file: {}", imageFile, e);
                            return null;
                        }
                    })
                    .filter(Objects::nonNull)
                    .collect(Collectors.toList());
        } catch (IOException e) {
            log.error("Failed to get images for document: {}", documentId, e);
            return new ArrayList<>();
        }
    }

    /**
     * ä»å›¾ç‰‡æ–‡ä»¶å’Œå…ƒæ•°æ®æ–‡ä»¶åŠ è½½ Image å¯¹è±¡
     */
    private Image loadImageFromFiles(Path imageFile, Path metadataFile) throws IOException {
        // è¯»å–å›¾ç‰‡äºŒè¿›åˆ¶æ•°æ®
        byte[] imageData = Files.readAllBytes(imageFile);

        // è¯»å–å…ƒæ•°æ®
        String metadataJson = new String(Files.readAllBytes(metadataFile), java.nio.charset.StandardCharsets.UTF_8);

        // è§£æå…ƒæ•°æ® (ç®€å•çš„ JSON è§£æ)
        String id = extractJsonValue(metadataJson, "id");
        String documentId = extractJsonValue(metadataJson, "documentId");
        String format = extractJsonValue(metadataJson, "format");
        Integer width = extractJsonIntValue(metadataJson, "width");
        Integer height = extractJsonIntValue(metadataJson, "height");
        Integer pageNumber = extractJsonIntValue(metadataJson, "pageNumber");

        return Image.builder()
                .id(id)
                .documentId(documentId)
                .data(imageData)
                .format(format)
                .width(width)
                .height(height)
                .pageNumber(pageNumber)
                .build();
    }

    /**
     * ä» JSON å­—ç¬¦ä¸²ä¸­æå–å­—ç¬¦ä¸²å€¼
     */
    private String extractJsonValue(String json, String key) {
        String pattern = "\"" + key + "\": \"";
        int start = json.indexOf(pattern);
        if (start == -1) return null;
        start += pattern.length();
        int end = json.indexOf("\"", start);
        if (end == -1) return null;
        return json.substring(start, end);
    }

    /**
     * ä» JSON å­—ç¬¦ä¸²ä¸­æå–æ•´æ•°å€¼
     */
    private Integer extractJsonIntValue(String json, String key) {
        String pattern = "\"" + key + "\": ";
        int start = json.indexOf(pattern);
        if (start == -1) return null;
        start += pattern.length();
        int end = json.indexOf(",", start);
        if (end == -1) {
            end = json.indexOf("\n", start);
        }
        if (end == -1) return null;
        try {
            return Integer.parseInt(json.substring(start, end).trim());
        } catch (NumberFormatException e) {
            return null;
        }
    }

    // ...existing code...

    @Override
    public void deleteImage(String imageId) {
        try {
            Files.walk(imagesPath, 2)
                    .filter(p -> p.toString().contains(imageId))
                    .forEach(p -> {
                        try {
                            Files.delete(p);
                            log.debug("Deleted image: {}", imageId);
                        } catch (IOException e) {
                            log.error("Failed to delete image: {}", imageId, e);
                        }
                    });
        } catch (IOException e) {
            log.error("Failed to delete image: {}", imageId, e);
        }
    }

    @Override
    public void deleteImagesByDocument(String documentId) {
        try {
            Path docImageDir = imagesPath.resolve(documentId);
            if (Files.exists(docImageDir)) {
                Files.walk(docImageDir)
                        .sorted(Comparator.reverseOrder())
                        .forEach(p -> {
                            try {
                                Files.delete(p);
                            } catch (IOException e) {
                                log.error("Failed to delete: {}", p, e);
                            }
                        });
                log.info("Deleted all images for document: {}", documentId);
            }
        } catch (IOException e) {
            log.error("Failed to delete images for document: {}", documentId, e);
        }
    }

    /**
     * é€šè¿‡å“ˆå¸Œå€¼æŸ¥æ‰¾å›¾ç‰‡ï¼ˆç”¨äºå»é‡ï¼‰â­ NEW
     */
    @Override
    public Optional<String> findImageByHash(String imageHash) {
        try {
            // éå†æ‰€æœ‰å›¾ç‰‡å…ƒæ•°æ®æ–‡ä»¶ï¼ŒæŸ¥æ‰¾åŒ¹é…çš„å“ˆå¸Œå€¼
            List<Path> metadataFiles = Files.walk(imagesPath, 3)
                    .filter(Files::isRegularFile)
                    .filter(p -> p.getFileName().toString().endsWith(".meta"))
                    .toList();

            for (Path metadataFile : metadataFiles) {
                try {
                    String metadataJson = new String(Files.readAllBytes(metadataFile),
                            java.nio.charset.StandardCharsets.UTF_8);

                    // æ£€æŸ¥æ˜¯å¦åŒ…å«åŒ¹é…çš„å“ˆå¸Œå€¼
                    if (metadataJson.contains("\"imageHash\": \"" + imageHash + "\"")) {
                        // æå– imageIdï¼ˆå‡è®¾æ ¼å¼ä¸º "imageId": "xxx_p001_i000"ï¼‰
                        int startIdx = metadataJson.indexOf("\"imageHash\"");
                        if (startIdx > 0) {
                            // å¾€å‰æ‰¾ imageId
                            String beforeHash = metadataJson.substring(0, startIdx);
                            int idStartIdx = beforeHash.lastIndexOf("\"imageId\": \"");
                            if (idStartIdx > 0) {
                                int idEndIdx = beforeHash.indexOf("\"", idStartIdx + 13);
                                if (idEndIdx > 0) {
                                    // å®é™…ä¸Šä»æ–‡ä»¶åæå–æ›´ç®€å•
                                    String filename = metadataFile.getFileName().toString();
                                    String imageId = filename.replace(".meta", "").replace(".png", "")
                                            .replace(".jpg", "").replace(".jpeg", "");

                                    log.debug("ğŸ” æ‰¾åˆ°é‡å¤å›¾ç‰‡: hash={}, imageId={}",
                                            imageHash.substring(0, 16), imageId);
                                    return Optional.of(imageId);
                                }
                            }
                        }
                    }
                } catch (IOException e) {
                    log.error("Failed to read metadata file: {}", metadataFile, e);
                }
            }

            return Optional.empty();
        } catch (IOException e) {
            log.error("Failed to find image by hash", e);
            return Optional.empty();
        }
    }

    // ========== PPL Data Storage ==========

    @Override
    public String savePPLData(String documentId, PPLData data) {
        try {
            Path docPplDir = pplPath.resolve(documentId);
            Files.createDirectories(docPplDir);

            Path pplFile = docPplDir.resolve("ppl.json");  // ä½¿ç”¨ .json åç¼€ â­

            // å°† PPL æ•°æ®è½¬æ¢ä¸º JSON å¹¶ä¿å­˜
            String jsonContent = buildPPLDataJson(data);
            Files.write(pplFile, jsonContent.getBytes(java.nio.charset.StandardCharsets.UTF_8));

            log.debug("Saved PPL data for document: {}", documentId);
            return documentId;
        } catch (IOException e) {
            log.error("Failed to save PPL data", e);
            return null;
        }
    }

    /**
     * æ„å»º PPL æ•°æ® JSON
     */
    private String buildPPLDataJson(PPLData data) {
        StringBuilder json = new StringBuilder();
        json.append("{\n");
        json.append("  \"documentId\": \"").append(data.getDocumentId()).append("\",\n");

        // probablePoints åˆ—è¡¨
        if (data.getProbablePoints() != null && !data.getProbablePoints().isEmpty()) {
            json.append("  \"probablePoints\": [");
            for (int i = 0; i < data.getProbablePoints().size(); i++) {
                if (i > 0) json.append(", ");
                json.append("\"").append(escapeJson(data.getProbablePoints().get(i))).append("\"");
            }
            json.append("],\n");
        }

        // scores æ˜ å°„
        if (data.getScores() != null && !data.getScores().isEmpty()) {
            json.append("  \"scores\": {\n");
            boolean first = true;
            for (Map.Entry<String, Float> entry : data.getScores().entrySet()) {
                if (!first) json.append(",\n");
                json.append("    \"").append(escapeJson(entry.getKey())).append("\": ").append(entry.getValue());
                first = false;
            }
            json.append("\n  },\n");
        }

        if (data.getModelVersion() != null) {
            json.append("  \"modelVersion\": \"").append(data.getModelVersion()).append("\",\n");
        }

        if (data.getAnalyzedAt() != null) {
            json.append("  \"analyzedAt\": ").append(data.getAnalyzedAt()).append(",\n");
        }

        // metadata
        if (data.getMetadata() != null && !data.getMetadata().isEmpty()) {
            json.append("  \"metadata\": ").append(mapToJson(data.getMetadata())).append(",\n");
        }

        json.append("  \"savedAt\": ").append(System.currentTimeMillis()).append("\n");
        json.append("}");
        return json.toString();
    }

    @Override
    public Optional<PPLData> getPPLData(String documentId) {
        try {
            Path pplFile = pplPath.resolve(documentId).resolve("ppl.json");  // è¯»å– .json æ–‡ä»¶ â­

            if (!Files.exists(pplFile)) {
                // å°è¯•è¯»å–æ—§æ ¼å¼ï¼ˆæ— åç¼€ï¼‰
                Path oldPplFile = pplPath.resolve(documentId).resolve("ppl");
                if (Files.exists(oldPplFile)) {
                    try (ObjectInputStream ois = new ObjectInputStream(new FileInputStream(oldPplFile.toFile()))) {
                        return Optional.of((PPLData) ois.readObject());
                    } catch (ClassNotFoundException e) {
                        log.error("Failed to deserialize old PPL data for document: {}", documentId, e);
                    }
                }
                return Optional.empty();
            }

            // è¯»å– JSON æ ¼å¼çš„ PPL æ•°æ®
            String jsonContent = new String(Files.readAllBytes(pplFile), java.nio.charset.StandardCharsets.UTF_8);
            PPLData data = parsePPLDataJson(jsonContent, documentId);
            return Optional.ofNullable(data);

        } catch (IOException e) {
            log.error("Failed to get PPL data for document: {}", documentId, e);
            return Optional.empty();
        }
    }

    /**
     * ä» JSON è§£æ PPL æ•°æ®
     */
    private PPLData parsePPLDataJson(String json, String documentId) {
        try {
            PPLData.PPLDataBuilder builder = PPLData.builder();
            builder.documentId(documentId);

            String modelVersion = extractJsonValue(json, "modelVersion");
            if (modelVersion != null) {
                builder.modelVersion(modelVersion);
            }

            Long analyzedAt = extractJsonLongValue(json, "analyzedAt");
            if (analyzedAt != null) {
                builder.analyzedAt(analyzedAt);
            }

            // è§£æ probablePoints æ•°ç»„ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            List<String> probablePoints = new ArrayList<>();
            int ppStart = json.indexOf("\"probablePoints\": [");
            if (ppStart != -1) {
                int ppEnd = json.indexOf("]", ppStart);
                if (ppEnd != -1) {
                    String ppArray = json.substring(ppStart + 19, ppEnd);
                    String[] points = ppArray.split("\",\\s*\"");
                    for (String point : points) {
                        String cleaned = point.replace("\"", "").trim();
                        if (!cleaned.isEmpty()) {
                            probablePoints.add(cleaned);
                        }
                    }
                }
            }
            builder.probablePoints(probablePoints);

            // è§£æ scores æ˜ å°„ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            Map<String, Float> scores = new HashMap<>();
            int scoresStart = json.indexOf("\"scores\": {");
            if (scoresStart != -1) {
                int scoresEnd = json.indexOf("}", scoresStart);
                if (scoresEnd != -1) {
                    String scoresBlock = json.substring(scoresStart + 11, scoresEnd);
                    String[] entries = scoresBlock.split(",");
                    for (String entry : entries) {
                        String[] kv = entry.split(":");
                        if (kv.length == 2) {
                            String key = kv[0].trim().replace("\"", "");
                            try {
                                Float value = Float.parseFloat(kv[1].trim());
                                scores.put(key, value);
                            } catch (NumberFormatException ignored) {}
                        }
                    }
                }
            }
            builder.scores(scores);

            return builder.build();
        } catch (Exception e) {
            log.error("Failed to parse PPL JSON", e);
            return null;
        }
    }

    /**
     * è½¬ä¹‰ JSON å­—ç¬¦ä¸²ä¸­çš„ç‰¹æ®Šå­—ç¬¦
     */
    private String escapeJson(String str) {
        if (str == null) return "";
        return str.replace("\\", "\\\\")
                  .replace("\"", "\\\"")
                  .replace("\n", "\\n")
                  .replace("\r", "\\r")
                  .replace("\t", "\\t");
    }

    @Override
    public void deletePPLData(String documentId) {
        try {
            Path docPplDir = pplPath.resolve(documentId);
            if (Files.exists(docPplDir)) {
                // åˆ é™¤æ•´ä¸ªç›®å½•ï¼ˆåŒ…å«æ–°æ—§æ ¼å¼ï¼‰
                Files.walk(docPplDir)
                        .sorted(Comparator.reverseOrder())
                        .forEach(p -> {
                            try {
                                Files.delete(p);
                            } catch (IOException e) {
                                log.error("Failed to delete: {}", p, e);
                            }
                        });
                log.info("Deleted PPL data for document: {}", documentId);
            }
        } catch (IOException e) {
            log.error("Failed to delete PPL data for document: {}", documentId, e);
        }
    }

    // ========== Optimization Data Storage (é€šç”¨RAGä¼˜åŒ–æ•°æ®) ==========

    @Override
    public String saveOptimizationData(String documentId, OptimizationData data) {
        try {
            Path docOptDir = optimizationPath.resolve(documentId);
            Files.createDirectories(docOptDir);

            // ä½¿ç”¨ä¼˜åŒ–ç±»å‹ä½œä¸ºæ–‡ä»¶åï¼Œæ·»åŠ  .json åç¼€ â­
            String fileName = data.getOptimizationType() + ".json";
            Path optFile = docOptDir.resolve(fileName);

            // å°† Optimization æ•°æ®è½¬æ¢ä¸º JSON å¹¶ä¿å­˜
            String jsonContent = buildOptimizationDataJson(data);
            Files.write(optFile, jsonContent.getBytes(java.nio.charset.StandardCharsets.UTF_8));

            log.debug("Saved {} optimization data for document: {}", data.getOptimizationType(), documentId);
            return documentId + ":" + data.getOptimizationType();
        } catch (IOException e) {
            log.error("Failed to save optimization data", e);
            return null;
        }
    }

    /**
     * æ„å»º Optimization æ•°æ® JSON
     */
    private String buildOptimizationDataJson(OptimizationData data) {
        StringBuilder json = new StringBuilder();
        json.append("{\n");
        json.append("  \"documentId\": \"").append(data.getDocumentId()).append("\",\n");
        json.append("  \"optimizationType\": \"").append(data.getOptimizationType()).append("\",\n");

        if (data.getAlgorithmVersion() != null) {
            json.append("  \"algorithmVersion\": \"").append(data.getAlgorithmVersion()).append("\",\n");
        }

        if (data.getProcessedAt() != null) {
            json.append("  \"processedAt\": ").append(data.getProcessedAt()).append(",\n");
        }

        // data æ˜ å°„
        if (data.getData() != null && !data.getData().isEmpty()) {
            json.append("  \"data\": ").append(mapToJson(data.getData())).append(",\n");
        }

        // metadata æ˜ å°„
        if (data.getMetadata() != null && !data.getMetadata().isEmpty()) {
            json.append("  \"metadata\": ").append(mapToJson(data.getMetadata())).append(",\n");
        }

        // metrics æ˜ å°„
        if (data.getMetrics() != null && !data.getMetrics().isEmpty()) {
            json.append("  \"metrics\": {\n");
            boolean first = true;
            for (Map.Entry<String, Double> entry : data.getMetrics().entrySet()) {
                if (!first) json.append(",\n");
                json.append("    \"").append(escapeJson(entry.getKey())).append("\": ").append(entry.getValue());
                first = false;
            }
            json.append("\n  },\n");
        }

        json.append("  \"savedAt\": ").append(System.currentTimeMillis()).append("\n");
        json.append("}");
        return json.toString();
    }

    @Override
    public Optional<OptimizationData> getOptimizationData(String documentId, String optimizationType) {
        try {
            Path optFile = optimizationPath.resolve(documentId).resolve(optimizationType + ".json");  // è¯»å– .json æ–‡ä»¶ â­

            if (!Files.exists(optFile)) {
                // å°è¯•è¯»å–æ—§æ ¼å¼ï¼ˆæ— åç¼€ï¼‰
                Path oldOptFile = optimizationPath.resolve(documentId).resolve(optimizationType);
                if (Files.exists(oldOptFile)) {
                    try (ObjectInputStream ois = new ObjectInputStream(new FileInputStream(oldOptFile.toFile()))) {
                        return Optional.of((OptimizationData) ois.readObject());
                    } catch (ClassNotFoundException e) {
                        log.error("Failed to deserialize old optimization data: {}", optimizationType, e);
                    }
                }
                return Optional.empty();
            }

            // è¯»å– JSON æ ¼å¼çš„ä¼˜åŒ–æ•°æ®
            String jsonContent = new String(Files.readAllBytes(optFile), java.nio.charset.StandardCharsets.UTF_8);
            OptimizationData data = parseOptimizationDataJson(jsonContent);
            return Optional.ofNullable(data);

        } catch (IOException e) {
            log.error("Failed to get {} optimization data for document: {}", optimizationType, documentId, e);
            return Optional.empty();
        }
    }

    /**
     * ä» JSON è§£æ Optimization æ•°æ®
     */
    private OptimizationData parseOptimizationDataJson(String json) {
        try {
            OptimizationData.OptimizationDataBuilder builder = OptimizationData.builder();

            String documentId = extractJsonValue(json, "documentId");
            String optimizationType = extractJsonValue(json, "optimizationType");
            String algorithmVersion = extractJsonValue(json, "algorithmVersion");
            Long processedAt = extractJsonLongValue(json, "processedAt");

            builder.documentId(documentId);
            builder.optimizationType(optimizationType);
            if (algorithmVersion != null) {
                builder.algorithmVersion(algorithmVersion);
            }
            if (processedAt != null) {
                builder.processedAt(processedAt);
            }

            // æ³¨æ„ï¼šdata, metadata, metrics çš„å®Œæ•´è§£ææ¯”è¾ƒå¤æ‚
            // è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…ä½¿ç”¨æ—¶å¯èƒ½éœ€è¦æ›´å®Œå–„çš„ JSON è§£æåº“
            builder.data(new HashMap<>());
            builder.metadata(new HashMap<>());
            builder.metrics(new HashMap<>());

            return builder.build();
        } catch (Exception e) {
            log.error("Failed to parse Optimization JSON", e);
            return null;
        }
    }

    @Override
    public List<OptimizationData> getAllOptimizationData(String documentId) {
        try {
            Path docOptDir = optimizationPath.resolve(documentId);
            if (!Files.exists(docOptDir)) {
                return Collections.emptyList();
            }

            return Files.list(docOptDir)
                    .filter(Files::isRegularFile)
                    .map(p -> {
                        try {
                            // ä¼˜å…ˆå°è¯•è¯»å– JSON æ ¼å¼
                            if (p.getFileName().toString().endsWith(".json")) {
                                String jsonContent = new String(Files.readAllBytes(p), java.nio.charset.StandardCharsets.UTF_8);
                                return parseOptimizationDataJson(jsonContent);
                            } else {
                                // å…¼å®¹æ—§æ ¼å¼ï¼šå°è¯•ååºåˆ—åŒ–
                                try (ObjectInputStream ois = new ObjectInputStream(new FileInputStream(p.toFile()))) {
                                    return (OptimizationData) ois.readObject();
                                } catch (ClassNotFoundException e) {
                                    log.error("Failed to read optimization file: {}", p, e);
                                    return null;
                                }
                            }
                        } catch (IOException e) {
                            log.error("Failed to read optimization file: {}", p, e);
                            return null;
                        }
                    })
                    .filter(Objects::nonNull)
                    .collect(Collectors.toList());
        } catch (IOException e) {
            log.error("Failed to list optimization data for document: {}", documentId, e);
            return Collections.emptyList();
        }
    }

    @Override
    public void deleteOptimizationData(String documentId, String optimizationType) {
        try {
            // å°è¯•åˆ é™¤ JSON æ ¼å¼æ–‡ä»¶
            Path optFile = optimizationPath.resolve(documentId).resolve(optimizationType + ".json");
            if (Files.exists(optFile)) {
                Files.delete(optFile);
                log.info("Deleted {} optimization data for document: {}", optimizationType, documentId);
                return;
            }

            // å°è¯•åˆ é™¤æ—§æ ¼å¼æ–‡ä»¶ï¼ˆæ— åç¼€ï¼‰
            Path oldOptFile = optimizationPath.resolve(documentId).resolve(optimizationType);
            if (Files.exists(oldOptFile)) {
                Files.delete(oldOptFile);
                log.info("Deleted {} optimization data (old format) for document: {}", optimizationType, documentId);
            }
        } catch (IOException e) {
            log.error("Failed to delete {} optimization data for document: {}", optimizationType, documentId, e);
        }
    }

    @Override
    public void deleteAllOptimizationData(String documentId) {
        try {
            Path docOptDir = optimizationPath.resolve(documentId);
            if (Files.exists(docOptDir)) {
                Files.walk(docOptDir)
                        .sorted(Comparator.reverseOrder())
                        .forEach(p -> {
                            try {
                                Files.delete(p);
                            } catch (IOException e) {
                                log.error("Failed to delete: {}", p, e);
                            }
                        });
                log.info("Deleted all optimization data for document: {}", documentId);
            }
        } catch (IOException e) {
            log.error("Failed to delete all optimization data for document: {}", documentId, e);
        }
    }

    // ========== Document Management ==========

    @Override
    public void cleanupDocument(String documentId) {
        deleteChunksByDocument(documentId);
        deleteImagesByDocument(documentId);
        deletePPLData(documentId);
        deleteAllOptimizationData(documentId);
        deleteExtractedText(documentId);  // â­ æ–°å¢ï¼šæ¸…ç†æå–æ–‡æœ¬
        log.info("Cleaned up all data for document: {}", documentId);
    }

    @Override
    public boolean documentExists(String documentId) {
        return Files.exists(chunksPath.resolve(documentId)) ||
                Files.exists(imagesPath.resolve(documentId)) ||
                Files.exists(pplPath.resolve(documentId)) ||
                Files.exists(optimizationPath.resolve(documentId));  // æ–°å¢
    }

    @Override
    public long getDocumentSize(String documentId) {
        try {
            long size = 0;

            // Calculate chunks size
            Path docChunkDir = chunksPath.resolve(documentId);
            if (Files.exists(docChunkDir)) {
                size += Files.walk(docChunkDir)
                        .filter(Files::isRegularFile)
                        .mapToLong(p -> {
                            try {
                                return Files.size(p);
                            } catch (IOException e) {
                                return 0;
                            }
                        })
                        .sum();
            }

            // Calculate images size
            Path docImageDir = imagesPath.resolve(documentId);
            if (Files.exists(docImageDir)) {
                size += Files.walk(docImageDir)
                        .filter(Files::isRegularFile)
                        .mapToLong(p -> {
                            try {
                                return Files.size(p);
                            } catch (IOException e) {
                                return 0;
                            }
                        })
                        .sum();
            }

            // Calculate PPL data size
            Path docPplDir = pplPath.resolve(documentId);
            if (Files.exists(docPplDir)) {
                size += Files.walk(docPplDir)
                        .filter(Files::isRegularFile)
                        .mapToLong(p -> {
                            try {
                                return Files.size(p);
                            } catch (IOException e) {
                                return 0;
                            }
                        })
                        .sum();
            }

            // Calculate optimization data size (æ–°å¢)
            Path docOptDir = optimizationPath.resolve(documentId);
            if (Files.exists(docOptDir)) {
                size += Files.walk(docOptDir)
                        .filter(Files::isRegularFile)
                        .mapToLong(p -> {
                            try {
                                return Files.size(p);
                            } catch (IOException e) {
                                return 0;
                            }
                        })
                        .sum();
            }

            return size;
        } catch (IOException e) {
            log.error("Failed to calculate document size for: {}", documentId, e);
            return 0;
        }
    }

    // ========== Statistics ==========

    @Override
    public StorageStatistics getStatistics() {
        try {
            long totalDocuments = 0;
            long totalChunks = 0;
            long totalImages = 0;
            long totalPPLData = 0;
            long totalSize = 0;

            // Count chunks
            if (Files.exists(chunksPath)) {
                totalDocuments = Files.list(chunksPath)
                        .filter(Files::isDirectory)
                        .count();

                totalChunks = Files.walk(chunksPath)
                        .filter(p -> p.toString().endsWith(".chunk"))
                        .count();

                totalSize += Files.walk(chunksPath)
                        .filter(Files::isRegularFile)
                        .mapToLong(p -> {
                            try {
                                return Files.size(p);
                            } catch (IOException e) {
                                return 0;
                            }
                        })
                        .sum();
            }

            // Count images
            if (Files.exists(imagesPath)) {
                totalImages = Files.walk(imagesPath)
                        .filter(p -> p.toString().endsWith(".img"))
                        .count();

                totalSize += Files.walk(imagesPath)
                        .filter(Files::isRegularFile)
                        .mapToLong(p -> {
                            try {
                                return Files.size(p);
                            } catch (IOException e) {
                                return 0;
                            }
                        })
                        .sum();
            }

            // Count PPL data
            if (Files.exists(pplPath)) {
                totalPPLData = Files.list(pplPath)
                        .filter(Files::isDirectory)
                        .count();

                totalSize += Files.walk(pplPath)
                        .filter(Files::isRegularFile)
                        .mapToLong(p -> {
                            try {
                                return Files.size(p);
                            } catch (IOException e) {
                                return 0;
                            }
                        })
                        .sum();
            }

            return StorageStatistics.builder()
                    .totalDocuments(totalDocuments)
                    .totalChunks(totalChunks)
                    .totalImages(totalImages)
                    .totalPPLData(totalPPLData)
                    .totalSize(totalSize)
                    .storageType("file")
                    .healthy(isHealthy())
                    .timestamp(System.currentTimeMillis())
                    .build();
        } catch (IOException e) {
            log.error("Failed to get statistics", e);
            return StorageStatistics.builder()
                    .storageType("file")
                    .healthy(false)
                    .timestamp(System.currentTimeMillis())
                    .build();
        }
    }

    @Override
    public boolean isHealthy() {
        return Files.exists(basePath) && Files.isWritable(basePath);
    }

    // ========== æ–‡æ¡£åˆ—è¡¨æŸ¥è¯¢æ–¹æ³• ==========

    @Override
    public List<DocumentMetadata> listAllDocuments() {
        try {
            return Files.walk(documentsPath)
                    .filter(Files::isRegularFile)
                    .map(this::buildDocumentMetadata)
                    .filter(Objects::nonNull)
                    .collect(Collectors.toList());
        } catch (IOException e) {
            log.error("Failed to list all documents", e);
            return Collections.emptyList();
        }
    }

    @Override
    public List<DocumentMetadata> listDocuments(int offset, int limit) {
        try {
            return Files.walk(documentsPath)
                    .filter(Files::isRegularFile)
                    .skip(offset)
                    .limit(limit)
                    .map(this::buildDocumentMetadata)
                    .filter(Objects::nonNull)
                    .collect(Collectors.toList());
        } catch (IOException e) {
            log.error("Failed to list documents with pagination", e);
            return Collections.emptyList();
        }
    }

    @Override
    public List<DocumentMetadata> searchDocuments(String keyword) {
        try {
            String lowerKeyword = keyword.toLowerCase();
            return Files.walk(documentsPath)
                    .filter(Files::isRegularFile)
                    .filter(p -> p.getFileName().toString().toLowerCase().contains(lowerKeyword))
                    .map(this::buildDocumentMetadata)
                    .filter(Objects::nonNull)
                    .collect(Collectors.toList());
        } catch (IOException e) {
            log.error("Failed to search documents", e);
            return Collections.emptyList();
        }
    }

    @Override
    public long getDocumentCount() {
        try {
            return Files.walk(documentsPath)
                    .filter(Files::isRegularFile)
                    .count();
        } catch (IOException e) {
            log.error("Failed to count documents", e);
            return 0;
        }
    }

    /**
     * ä»æ–‡ä»¶è·¯å¾„æ„å»ºæ–‡æ¡£å…ƒæ•°æ®
     */
    private DocumentMetadata buildDocumentMetadata(Path filePath) {
        try {
            Path relativePath = documentsPath.relativize(filePath);
            String relativePathStr = relativePath.toString().replace('\\', '/');
            String filename = filePath.getFileName().toString();

            // æå–æ–‡æ¡£IDï¼ˆä»æ–‡ä»¶åæ¨æ–­ï¼‰
            String documentId = "doc_" + filename;

            // è·å–æ–‡ä»¶å±æ€§
            long fileSize = Files.size(filePath);
            long lastModifiedTime = Files.getLastModifiedTime(filePath).toMillis();

            // è·å–æ–‡ä»¶ç±»å‹
            String fileType = getFileExtension(filename);

            // ç»Ÿè®¡åˆ†å—æ•°é‡
            int chunkCount = countChunks(filename);

            // ç»Ÿè®¡å›¾ç‰‡æ•°é‡
            int imageCount = countImages(filename);

            return DocumentMetadata.builder()
                    .documentId(documentId)
                    .filename(filename)
                    .relativePath(relativePathStr)
                    .fileSize(fileSize)
                    .fileType(fileType)
                    .uploadTime(new Date(lastModifiedTime))
                    .lastModified(new Date(lastModifiedTime))
                    .indexed(chunkCount > 0)  // æœ‰åˆ†å—è¯´æ˜å·²ç´¢å¼•
                    .chunkCount(chunkCount)
                    .imageCount(imageCount)
                    .storagePath(relativePathStr)
                    .build();
        } catch (IOException e) {
            log.error("Failed to build metadata for: {}", filePath, e);
            return null;
        }
    }

    /**
     * è·å–æ–‡ä»¶æ‰©å±•å
     */
    private String getFileExtension(String filename) {
        int lastDot = filename.lastIndexOf('.');
        if (lastDot > 0 && lastDot < filename.length() - 1) {
            return filename.substring(lastDot + 1);
        }
        return "";
    }

    /**
     * ç»Ÿè®¡æ–‡æ¡£çš„åˆ†å—æ•°é‡
     */
    private int countChunks(String filename) {
        try {
            Path docChunkDir = chunksPath.resolve(filename);
            if (!Files.exists(docChunkDir)) {
                return 0;
            }
            return (int) Files.list(docChunkDir)
                    .filter(Files::isRegularFile)
                    .filter(p -> p.getFileName().toString().startsWith("chunk_"))
                    .count();
        } catch (IOException e) {
            return 0;
        }
    }

    /**
     * ç»Ÿè®¡æ–‡æ¡£çš„å›¾ç‰‡æ•°é‡
     */
    private int countImages(String filename) {
        try {
            Path docImageDir = imagesPath.resolve(filename);
            if (!Files.exists(docImageDir)) {
                return 0;
            }
            return (int) Files.list(docImageDir)
                    .filter(Files::isRegularFile)
                    .count();
        } catch (IOException e) {
            return 0;
        }
    }

    // ========== æ–‡ä»¶ç³»ç»Ÿæµè§ˆå®ç° (File System Browse Implementation) ==========

    @Override
    public List<Map<String, Object>> listFiles(String virtualPath) {
        try {
            // å°†è™šæ‹Ÿè·¯å¾„æ˜ å°„åˆ°ç‰©ç†è·¯å¾„
            Path fullPath = resolvePath(virtualPath);

            // å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢è·¯å¾„éå†æ”»å‡»
            if (!isPathSafe(fullPath)) {
                throw new IllegalArgumentException("éæ³•è·¯å¾„: " + virtualPath);
            }

            if (!Files.exists(fullPath) || !Files.isDirectory(fullPath)) {
                log.warn("ç›®å½•ä¸å­˜åœ¨æˆ–ä¸æ˜¯ç›®å½•: {}", fullPath);
                return new ArrayList<>();
            }

            // åˆ—å‡ºæ–‡ä»¶å’Œæ–‡ä»¶å¤¹
            return Files.list(fullPath)
                    .map(p -> {
                        try {
                            Map<String, Object> item = new HashMap<>();
                            String fileName = p.getFileName().toString();
                            boolean isDirectory = Files.isDirectory(p);

                            // è®¡ç®—ç›¸å¯¹è·¯å¾„
                            String relativePath = basePath.relativize(p).toString().replace("\\", "/");

                            item.put("name", fileName);
                            item.put("type", isDirectory ? "directory" : "file");
                            item.put("path", relativePath);

                            if (!isDirectory) {
                                item.put("size", Files.size(p));
                                item.put("modified", Files.getLastModifiedTime(p).toMillis());
                            }

                            return item;
                        } catch (IOException e) {
                            log.error("è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {}", p, e);
                            return null;
                        }
                    })
                    .filter(Objects::nonNull)
                    .collect(Collectors.toList());

        } catch (IOException e) {
            log.error("åˆ—å‡ºæ–‡ä»¶å¤±è´¥: {}", virtualPath, e);
            throw new RuntimeException("åˆ—å‡ºæ–‡ä»¶å¤±è´¥: " + e.getMessage(), e);
        }
    }

    @Override
    public byte[] readFile(String virtualPath) {
        try {
            // å°†è™šæ‹Ÿè·¯å¾„æ˜ å°„åˆ°ç‰©ç†è·¯å¾„
            Path fullPath = resolvePath(virtualPath);

            // å®‰å…¨æ£€æŸ¥
            if (!isPathSafe(fullPath)) {
                throw new IllegalArgumentException("éæ³•è·¯å¾„: " + virtualPath);
            }

            if (!Files.exists(fullPath) || !Files.isRegularFile(fullPath)) {
                log.warn("æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸æ˜¯å¸¸è§„æ–‡ä»¶: {}", fullPath);
                return null;
            }

            return Files.readAllBytes(fullPath);

        } catch (IOException e) {
            log.error("è¯»å–æ–‡ä»¶å¤±è´¥: {}", virtualPath, e);
            throw new RuntimeException("è¯»å–æ–‡ä»¶å¤±è´¥: " + e.getMessage(), e);
        }
    }

    @Override
    public boolean deleteFile(String virtualPath) {
        try {
            // å°†è™šæ‹Ÿè·¯å¾„æ˜ å°„åˆ°ç‰©ç†è·¯å¾„
            Path fullPath = resolvePath(virtualPath);

            // å®‰å…¨æ£€æŸ¥
            if (!isPathSafe(fullPath)) {
                throw new IllegalArgumentException("éæ³•è·¯å¾„: " + virtualPath);
            }

            if (!Files.exists(fullPath)) {
                log.warn("æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {}", fullPath);
                return false;
            }

            // é€’å½’åˆ é™¤
            if (Files.isDirectory(fullPath)) {
                Files.walk(fullPath)
                        .sorted(Comparator.reverseOrder())
                        .forEach(p -> {
                            try {
                                Files.delete(p);
                            } catch (IOException e) {
                                log.error("åˆ é™¤å¤±è´¥: {}", p, e);
                            }
                        });
            } else {
                Files.delete(fullPath);
            }

            log.info("âœ… åˆ é™¤æˆåŠŸ: {}", virtualPath);
            return true;

        } catch (IOException e) {
            log.error("åˆ é™¤å¤±è´¥: {}", virtualPath, e);
            return false;
        }
    }

    @Override
    public boolean createDirectory(String virtualPath) {
        try {
            // å°†è™šæ‹Ÿè·¯å¾„æ˜ å°„åˆ°ç‰©ç†è·¯å¾„
            Path fullPath = resolvePath(virtualPath);

            // å®‰å…¨æ£€æŸ¥
            if (!isPathSafe(fullPath)) {
                throw new IllegalArgumentException("éæ³•è·¯å¾„: " + virtualPath);
            }

            if (Files.exists(fullPath)) {
                log.warn("æ–‡ä»¶å¤¹å·²å­˜åœ¨: {}", fullPath);
                return false;
            }

            Files.createDirectories(fullPath);
            log.info("âœ… åˆ›å»ºæ–‡ä»¶å¤¹æˆåŠŸ: {}", virtualPath);
            return true;

        } catch (IOException e) {
            log.error("åˆ›å»ºæ–‡ä»¶å¤¹å¤±è´¥: {}", virtualPath, e);
            return false;
        }
    }

    @Override
    public Map<String, Object> getStorageStats(String virtualPath) {
        try {
            // å°†è™šæ‹Ÿè·¯å¾„æ˜ å°„åˆ°ç‰©ç†è·¯å¾„
            Path fullPath = resolvePath(virtualPath);

            // å®‰å…¨æ£€æŸ¥
            if (!isPathSafe(fullPath)) {
                throw new IllegalArgumentException("éæ³•è·¯å¾„: " + virtualPath);
            }

            if (!Files.exists(fullPath)) {
                log.warn("è·¯å¾„ä¸å­˜åœ¨: {}", fullPath);
                return Map.of(
                        "totalFiles", 0L,
                        "totalFolders", 0L,
                        "totalSize", 0L
                );
            }

            // ç»Ÿè®¡æ–‡ä»¶æ•°é‡ã€æ–‡ä»¶å¤¹æ•°é‡ã€æ€»å¤§å°
            long[] stats = new long[3]; // [files, folders, size]

            Files.walk(fullPath)
                    .forEach(p -> {
                        try {
                            if (Files.isRegularFile(p)) {
                                stats[0]++; // æ–‡ä»¶æ•°
                                stats[2] += Files.size(p); // æ€»å¤§å°
                            } else if (Files.isDirectory(p) && !p.equals(fullPath)) {
                                stats[1]++; // æ–‡ä»¶å¤¹æ•°ï¼ˆä¸åŒ…æ‹¬æ ¹ç›®å½•ï¼‰
                            }
                        } catch (IOException e) {
                            log.error("ç»Ÿè®¡æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {}", p, e);
                        }
                    });

            return Map.of(
                    "totalFiles", stats[0],
                    "totalFolders", stats[1],
                    "totalSize", stats[2]
            );

        } catch (IOException e) {
            log.error("è·å–å­˜å‚¨ç»Ÿè®¡å¤±è´¥: {}", virtualPath, e);
            return Map.of(
                    "totalFiles", 0L,
                    "totalFolders", 0L,
                    "totalSize", 0L
            );
        }
    }

    /**
     * å°†è™šæ‹Ÿè·¯å¾„è§£æä¸ºç‰©ç†è·¯å¾„
     */
    private Path resolvePath(String virtualPath) {
        if (virtualPath == null || virtualPath.isEmpty()) {
            return basePath;
        }
        // ç§»é™¤å¼€å¤´çš„æ–œæ 
        String cleanPath = virtualPath.startsWith("/") ? virtualPath.substring(1) : virtualPath;
        return basePath.resolve(cleanPath).normalize();
    }

    /**
     * æ£€æŸ¥è·¯å¾„æ˜¯å¦å®‰å…¨ï¼ˆé˜²æ­¢è·¯å¾„éå†æ”»å‡»ï¼‰
     */
    private boolean isPathSafe(Path path) {
        try {
            Path normalizedPath = path.normalize();
            Path normalizedBase = basePath.normalize();
            return normalizedPath.startsWith(normalizedBase);
        } catch (Exception e) {
            log.error("è·¯å¾„å®‰å…¨æ£€æŸ¥å¤±è´¥", e);
            return false;
        }
    }
}
