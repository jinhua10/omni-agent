package top.yumbo.ai.omni.ppl.onnx;

import ai.djl.huggingface.tokenizers.Encoding;
import ai.djl.huggingface.tokenizers.HuggingFaceTokenizer;
import ai.onnxruntime.*;
import com.github.benmanes.caffeine.cache.Cache;
import com.github.benmanes.caffeine.cache.Caffeine;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
import org.springframework.stereotype.Service;

import jakarta.annotation.PostConstruct;
import jakarta.annotation.PreDestroy;
import java.nio.file.Paths;
import java.time.Duration;
import java.util.*;

/**
 * åŸºäº ONNX Runtime çš„ PPL æœåŠ¡å®ç°ï¼ˆç®€åŒ–ç‰ˆï¼‰
 *
 * ç”¨äºè®¡ç®—æ–‡æœ¬çš„å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰
 *
 * @author OmniAgent Team
 * @since 3.0.0
 */
@Slf4j
@Service
@ConditionalOnProperty(prefix = "ppl.onnx", name = "enabled", havingValue = "true")
public class PPLOnnxService {

    @Value("${ppl.onnx.model-path}")
    private String modelPath;

    @Value("${ppl.onnx.tokenizer-path}")
    private String tokenizerPath;

    @Value("${ppl.onnx.use-cache:true}")
    private boolean useCache;

    @Value("${ppl.onnx.cache-size:1000}")
    private int cacheSize;

    @Value("${ppl.onnx.cache-ttl:3600}")
    private int cacheTtl;

    // ONNX Runtime ç»„ä»¶
    private OrtEnvironment env;
    private OrtSession session;
    private HuggingFaceTokenizer tokenizer;

    // PPL ç¼“å­˜
    private Cache<String, Double> pplCache;

    @PostConstruct
    public void init() {
        log.info("ğŸš€ åˆå§‹åŒ– ONNX PPL æœåŠ¡");

        try {
            // 1. åˆå§‹åŒ– ONNX Runtime ç¯å¢ƒ
            this.env = OrtEnvironment.getEnvironment();
            log.info("âœ… ONNX Environment åˆ›å»ºæˆåŠŸ");

            // 2. åŠ è½½ ONNX æ¨¡å‹
            OrtSession.SessionOptions sessionOptions = new OrtSession.SessionOptions();
            sessionOptions.setOptimizationLevel(OrtSession.SessionOptions.OptLevel.BASIC_OPT);

            this.session = env.createSession(modelPath, sessionOptions);
            log.info("âœ… ONNX æ¨¡å‹åŠ è½½æˆåŠŸ: {}", modelPath);

            // 3. åŠ è½½ Tokenizer
            this.tokenizer = HuggingFaceTokenizer.newInstance(Paths.get(tokenizerPath));
            log.info("âœ… Tokenizer åŠ è½½æˆåŠŸ: {}", tokenizerPath);

            // 4. åˆå§‹åŒ–ç¼“å­˜
            if (useCache) {
                this.pplCache = Caffeine.newBuilder()
                        .maximumSize(cacheSize)
                        .expireAfterWrite(Duration.ofSeconds(cacheTtl))
                        .recordStats()
                        .build();
                log.info("âœ… PPL ç¼“å­˜åˆå§‹åŒ–: size={}, ttl={}s", cacheSize, cacheTtl);
            }

            log.info("ğŸ‰ ONNX PPL æœåŠ¡åˆå§‹åŒ–å®Œæˆ");

        } catch (Exception e) {
            log.error("âŒ ONNX PPL æœåŠ¡åˆå§‹åŒ–å¤±è´¥", e);
            throw new RuntimeException("ONNX PPL æœåŠ¡åˆå§‹åŒ–å¤±è´¥", e);
        }
    }

    /**
     * è®¡ç®—æ–‡æœ¬çš„å›°æƒ‘åº¦
     */
    public double calculatePerplexity(String text) {
        if (text == null || text.trim().isEmpty()) {
            return Double.MAX_VALUE;
        }

        // æ£€æŸ¥ç¼“å­˜
        if (pplCache != null) {
            Double cached = pplCache.getIfPresent(text);
            if (cached != null) {
                return cached;
            }
        }

        List<OnnxTensor> tensorsToClose = new ArrayList<>();

        try {
            // 1. Tokenize
            Encoding encoding = tokenizer.encode(text);
            long[] inputIds = encoding.getIds();
            long[] attentionMask = encoding.getAttentionMask();

            if (inputIds.length == 0) {
                return Double.MAX_VALUE;
            }

            // 2. å‡†å¤‡ ONNX è¾“å…¥
            Map<String, OnnxTensor> inputs = new HashMap<>();
            int seqLen = inputIds.length;

            // è½¬æ¢ä¸º [1, seq_len] çš„å¼ é‡
            long[][] inputIdsArray = new long[1][seqLen];
            inputIdsArray[0] = inputIds;

            long[][] attentionMaskArray = new long[1][seqLen];
            attentionMaskArray[0] = attentionMask;

            OnnxTensor inputIdsTensor = OnnxTensor.createTensor(env, inputIdsArray);
            OnnxTensor attentionMaskTensor = OnnxTensor.createTensor(env, attentionMaskArray);

            tensorsToClose.add(inputIdsTensor);
            tensorsToClose.add(attentionMaskTensor);

            inputs.put("input_ids", inputIdsTensor);
            inputs.put("attention_mask", attentionMaskTensor);

            // 3. æ¨¡å‹æ¨ç†
            try (OrtSession.Result results = session.run(inputs)) {
                // è·å– logits
                OnnxValue logitsValue = results.get(0);
                float[][][] logits = (float[][][]) logitsValue.getValue();

                // 4. è®¡ç®—å›°æƒ‘åº¦
                double totalLoss = 0.0;
                int validTokens = 0;

                // å¯¹æ¯ä¸ªä½ç½®è®¡ç®— cross-entropy loss
                for (int i = 0; i < inputIds.length - 1; i++) {
                    int targetId = (int) inputIds[i + 1];
                    float[] probs = logits[0][i];

                    // Softmax å½’ä¸€åŒ–
                    float maxLogit = Float.NEGATIVE_INFINITY;
                    for (float logit : probs) {
                        maxLogit = Math.max(maxLogit, logit);
                    }

                    double sumExp = 0.0;
                    for (float logit : probs) {
                        sumExp += Math.exp(logit - maxLogit);
                    }

                    double logProb = probs[targetId] - maxLogit - Math.log(sumExp);
                    totalLoss -= logProb;
                    validTokens++;
                }

                // PPL = exp(average loss)
                double ppl = validTokens > 0 ? Math.exp(totalLoss / validTokens) : Double.MAX_VALUE;

                // æ¸…ç†èµ„æº
                for (OnnxTensor tensor : tensorsToClose) {
                    try {
                        tensor.close();
                    } catch (Exception ignored) {}
                }

                // ç¼“å­˜ç»“æœ
                if (pplCache != null) {
                    pplCache.put(text, ppl);
                }

                return ppl;
            }

        } catch (Exception e) {
            log.error("è®¡ç®—å›°æƒ‘åº¦å¤±è´¥: {}", e.getMessage(), e);
            return Double.MAX_VALUE;
        }
    }

    /**
     * å¥åº·æ£€æŸ¥
     */
    public boolean isHealthy() {
        return env != null && session != null && tokenizer != null;
    }

    @PreDestroy
    public void destroy() {
        try {
            if (session != null) {
                session.close();
            }
            if (env != null) {
                env.close();
            }
            log.info("âœ… ONNX PPL æœåŠ¡å·²å…³é—­");
        } catch (Exception e) {
            log.error("å…³é—­ ONNX PPL æœåŠ¡å¤±è´¥", e);
        }
    }
}

