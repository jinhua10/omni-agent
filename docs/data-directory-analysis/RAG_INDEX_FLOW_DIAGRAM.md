# data/rag-index 生成流程图

## 🎯 完整流程可视化

### 1. 应用启动流程

```
┌─────────────────────────────────────────────────────────────┐
│                     应用启动                                  │
│                        ↓                                     │
│         LuceneRAGService.init() 方法执行                      │
│                        ↓                                     │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ 1. 检查并创建目录: data/rag-index/                   │   │
│  │    Files.createDirectories(indexPath)                │   │
│  └─────────────────────────────────────────────────────┘   │
│                        ↓                                     │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ 2. 清理锁文件（如果存在）                            │   │
│  │    Files.delete("write.lock")                        │   │
│  └─────────────────────────────────────────────────────┘   │
│                        ↓                                     │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ 3. 打开 Lucene Directory                             │   │
│  │    directory = FSDirectory.open(indexPath)           │   │
│  └─────────────────────────────────────────────────────┘   │
│                        ↓                                     │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ 4. 创建 StandardAnalyzer（中文分词器）               │   │
│  │    analyzer = new StandardAnalyzer()                 │   │
│  └─────────────────────────────────────────────────────┘   │
│                        ↓                                     │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ 5. 创建 IndexWriter                                  │   │
│  │    config = new IndexWriterConfig(analyzer)          │   │
│  │    indexWriter = new IndexWriter(directory, config)  │   │
│  └─────────────────────────────────────────────────────┘   │
│                        ↓                                     │
│  ┌─────────────────────────────────────────────────────┐   │
│  │ 6. 提交初始索引                                      │   │
│  │    indexWriter.commit()  ⭐ 生成初始文件             │   │
│  └─────────────────────────────────────────────────────┘   │
│                        ↓                                     │
│               生成的文件：                                   │
│         ├─ segments_*  (段元数据)                           │
│         └─ write.lock  (写锁)                               │
└─────────────────────────────────────────────────────────────┘
```

---

### 2. 文档索引流程

```
┌──────────────────────────────────────────────────────────────┐
│               用户调用: indexDocument(doc)                     │
│                           ↓                                   │
│  ┌────────────────────────────────────────────────────────┐  │
│  │ 步骤1: 生成文档ID（如果没有）                          │  │
│  │  if (doc.getId() == null) {                            │  │
│  │      doc.setId(UUID.randomUUID().toString())           │  │
│  │  }                                                      │  │
│  └────────────────────────────────────────────────────────┘  │
│                           ↓                                   │
│  ┌────────────────────────────────────────────────────────┐  │
│  │ 步骤2: 转换为 Lucene Document                          │  │
│  │  LuceneDoc luceneDoc = new Document()                  │  │
│  │    .add(StringField("id", doc.getId()))                │  │
│  │    .add(TextField("title", doc.getTitle()))            │  │
│  │    .add(TextField("content", doc.getContent()))        │  │
│  │    .add(StringField("source", doc.getSource()))        │  │
│  └────────────────────────────────────────────────────────┘  │
│                           ↓                                   │
│              【分词处理 - StandardAnalyzer】                   │
│  ┌────────────────────────────────────────────────────────┐  │
│  │  title: "机器学习入门"                                  │  │
│  │    ↓                                                    │  │
│  │  分词结果: ["机器", "学习", "入门"]                     │  │
│  │                                                         │  │
│  │  content: "机器学习是人工智能的重要分支..."            │  │
│  │    ↓                                                    │  │
│  │  分词结果: ["机器", "学习", "是", "人工智能", ...]     │  │
│  └────────────────────────────────────────────────────────┘  │
│                           ↓                                   │
│  ┌────────────────────────────────────────────────────────┐  │
│  │ 步骤3: 删除旧文档（如果存在）                          │  │
│  │  indexWriter.deleteDocuments(new Term("id", docId))    │  │
│  └────────────────────────────────────────────────────────┘  │
│                           ↓                                   │
│  ┌────────────────────────────────────────────────────────┐  │
│  │ 步骤4: 添加文档到索引                                  │  │
│  │  indexWriter.addDocument(luceneDoc)                    │  │
│  │    ↓                                                    │  │
│  │  【内存缓冲区】                                         │  │
│  │    文档暂存在 RAM Buffer (256MB)                       │  │
│  └────────────────────────────────────────────────────────┘  │
│                           ↓                                   │
│  ┌────────────────────────────────────────────────────────┐  │
│  │ 步骤5: 提交事务                                        │  │
│  │  indexWriter.commit()  ⭐ 刷新到磁盘                   │  │
│  └────────────────────────────────────────────────────────┘  │
│                           ↓                                   │
│              【生成/更新索引文件】                            │
│  ┌────────────────────────────────────────────────────────┐  │
│  │  创建新段（例如 _35）:                                 │  │
│  │    ├─ _35_Lucene99_0.doc  (倒排索引 - 文档ID)         │  │
│  │    ├─ _35_Lucene99_0.pos  (词项位置)                  │  │
│  │    ├─ _35_Lucene99_0.tim  (词项索引)                  │  │
│  │    ├─ _35_Lucene99_0.tip  (词项指针)                  │  │
│  │    ├─ _35.fdt             (字段数据)                   │  │
│  │    ├─ _35.fdx             (字段索引)                   │  │
│  │    ├─ _35.fnm             (字段名称)                   │  │
│  │    └─ _35.si              (段信息)                     │  │
│  │                                                         │  │
│  │  更新 segments_* 文件                                  │  │
│  └────────────────────────────────────────────────────────┘  │
│                           ↓                                   │
│  ┌────────────────────────────────────────────────────────┐  │
│  │ 步骤6: 刷新搜索器                                      │  │
│  │  searcherManager.maybeRefresh()                        │  │
│  │    使新索引对搜索可见                                  │  │
│  └────────────────────────────────────────────────────────┘  │
│                           ↓                                   │
│                     ✅ 索引完成                               │
└──────────────────────────────────────────────────────────────┘
```

---

### 3. 倒排索引生成详解

```
原始文档:
┌──────────────────────────────────────────┐
│ ID: doc-001                              │
│ Title: "机器学习入门"                     │
│ Content: "机器学习是人工智能的重要分支"  │
└──────────────────────────────────────────┘
             ↓
      【分词处理】
             ↓
┌──────────────────────────────────────────┐
│ 分词结果:                                 │
│   Title: ["机器", "学习", "入门"]        │
│   Content: ["机器", "学习", "是",        │
│             "人工智能", "重要", "分支"]  │
└──────────────────────────────────────────┘
             ↓
    【构建倒排索引】
             ↓
┌──────────────────────────────────────────────────────┐
│ 倒排索引数据结构:                                     │
│                                                       │
│ 词项 "机器":                                          │
│   ├─ 文档列表: [doc-001]                             │
│   ├─ 词频(TF): 2                                     │
│   └─ 位置: title[0], content[0]                      │
│                                                       │
│ 词项 "学习":                                          │
│   ├─ 文档列表: [doc-001]                             │
│   ├─ 词频(TF): 2                                     │
│   └─ 位置: title[1], content[1]                      │
│                                                       │
│ 词项 "人工智能":                                      │
│   ├─ 文档列表: [doc-001]                             │
│   ├─ 词频(TF): 1                                     │
│   └─ 位置: content[3]                                │
│                                                       │
│ 词项 "入门":                                          │
│   ├─ 文档列表: [doc-001]                             │
│   ├─ 词频(TF): 1                                     │
│   └─ 位置: title[2]                                  │
└──────────────────────────────────────────────────────┘
             ↓
      【写入磁盘文件】
             ↓
┌──────────────────────────────────────────┐
│ _35_Lucene99_0.doc                       │
│   词项 "机器" → 文档ID列表: [doc-001]   │
│   词项 "学习" → 文档ID列表: [doc-001]   │
│                                          │
│ _35_Lucene99_0.pos                       │
│   doc-001中"机器"的位置: [0(title), 0]  │
│   doc-001中"学习"的位置: [1(title), 1]  │
│                                          │
│ _35_Lucene99_0.tim                       │
│   词项索引树（快速定位词项）             │
│                                          │
│ _35.fdt                                  │
│   doc-001的完整内容（序列化存储）        │
└──────────────────────────────────────────┘
```

---

### 4. 搜索流程

```
┌──────────────────────────────────────────────────────────────┐
│            用户查询: "机器学习"                                │
│                          ↓                                    │
│  ┌────────────────────────────────────────────────────────┐  │
│  │ 步骤1: 查询分词                                        │  │
│  │   analyzer.tokenize("机器学习")                        │  │
│  │     ↓                                                   │  │
│  │   结果: ["机器", "学习"]                               │  │
│  └────────────────────────────────────────────────────────┘  │
│                          ↓                                    │
│  ┌────────────────────────────────────────────────────────┐  │
│  │ 步骤2: 查询倒排索引                                    │  │
│  │   读取 _35_Lucene99_0.tim (词项索引)                   │  │
│  │     ↓                                                   │  │
│  │   "机器" → 指向 _35_Lucene99_0.doc                     │  │
│  │     ↓                                                   │  │
│  │   文档列表: [doc-001, doc-005, doc-042]                │  │
│  │                                                         │  │
│  │   "学习" → 指向 _35_Lucene99_0.doc                     │  │
│  │     ↓                                                   │  │
│  │   文档列表: [doc-001, doc-003, doc-042]                │  │
│  └────────────────────────────────────────────────────────┘  │
│                          ↓                                    │
│  ┌────────────────────────────────────────────────────────┐  │
│  │ 步骤3: 计算文档相关性评分                              │  │
│  │   BM25算法:                                            │  │
│  │     doc-001: 同时包含"机器"和"学习" → 分数 8.5        │  │
│  │     doc-042: 同时包含"机器"和"学习" → 分数 7.2        │  │
│  │     doc-005: 只包含"机器"           → 分数 3.1        │  │
│  │     doc-003: 只包含"学习"           → 分数 2.8        │  │
│  └────────────────────────────────────────────────────────┘  │
│                          ↓                                    │
│  ┌────────────────────────────────────────────────────────┐  │
│  │ 步骤4: 读取文档内容                                    │  │
│  │   读取 _35.fdt (字段数据)                              │  │
│  │     ↓                                                   │  │
│  │   doc-001: {                                           │  │
│  │     title: "机器学习入门",                             │  │
│  │     content: "机器学习是...",                          │  │
│  │     source: "ml-book.pdf"                              │  │
│  │   }                                                     │  │
│  └────────────────────────────────────────────────────────┘  │
│                          ↓                                    │
│  ┌────────────────────────────────────────────────────────┐  │
│  │ 步骤5: 返回 TOP-K 结果                                 │  │
│  │   [doc-001, doc-042, doc-005, doc-003]                │  │
│  │   (按评分降序排列)                                     │  │
│  └────────────────────────────────────────────────────────┘  │
│                          ↓                                    │
│                      ✅ 搜索完成                              │
└──────────────────────────────────────────────────────────────┘
```

---

### 5. 段合并流程

```
┌──────────────────────────────────────────────────────────────┐
│                    初始状态（多个小段）                         │
│                                                               │
│  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐               │
│  │ _33 │  │ _34 │  │ _35 │  │ _36 │  │ _37 │               │
│  │ 20  │  │ 15  │  │ 25  │  │ 10  │  │ 18  │ 文档数         │
│  └─────┘  └─────┘  └─────┘  └─────┘  └─────┘               │
│                                                               │
│                          ↓                                    │
│              【后台线程触发段合并】                            │
│         (当小段数量达到阈值时自动触发)                         │
│                          ↓                                    │
│  ┌────────────────────────────────────────────────────────┐  │
│  │ TieredMergePolicy 决策:                                │  │
│  │   - 选择大小相近的段                                   │  │
│  │   - _33 + _34 + _36 → _40 (45个文档)                  │  │
│  │   - _35 + _37 → _41 (43个文档)                        │  │
│  └────────────────────────────────────────────────────────┘  │
│                          ↓                                    │
│                   【执行合并操作】                             │
│  ┌────────────────────────────────────────────────────────┐  │
│  │ 1. 创建新段文件:                                       │  │
│  │    _40_Lucene99_0.doc                                  │  │
│  │    _40_Lucene99_0.pos                                  │  │
│  │    _40.fdt                                             │  │
│  │    _40.fdx                                             │  │
│  │    _40.si                                              │  │
│  │                                                         │  │
│  │ 2. 合并倒排索引:                                       │  │
│  │    _33.doc + _34.doc + _36.doc → _40.doc              │  │
│  │                                                         │  │
│  │ 3. 合并存储数据:                                       │  │
│  │    _33.fdt + _34.fdt + _36.fdt → _40.fdt              │  │
│  └────────────────────────────────────────────────────────┘  │
│                          ↓                                    │
│                   【更新段元数据】                             │
│  ┌────────────────────────────────────────────────────────┐  │
│  │ segments_* 文件更新:                                   │  │
│  │   移除: _33, _34, _36                                  │  │
│  │   添加: _40                                            │  │
│  └────────────────────────────────────────────────────────┘  │
│                          ↓                                    │
│                   【删除旧段文件】                             │
│  ┌────────────────────────────────────────────────────────┐  │
│  │ 删除:                                                  │  │
│  │   _33.*  (所有 _33 相关文件)                          │  │
│  │   _34.*  (所有 _34 相关文件)                          │  │
│  │   _36.*  (所有 _36 相关文件)                          │  │
│  └────────────────────────────────────────────────────────┘  │
│                          ↓                                    │
│                  合并后状态（更少的大段）                      │
│                                                               │
│            ┌─────┐  ┌─────┐                                  │
│            │ _40 │  │ _41 │                                  │
│            │ 45  │  │ 43  │ 文档数                            │
│            └─────┘  └─────┘                                  │
│                                                               │
│  优势:                                                        │
│    ✅ 文件数量减少（减少文件句柄）                            │
│    ✅ 搜索性能提升（减少段合并开销）                          │
│    ✅ 磁盘空间优化（删除重复数据）                            │
└──────────────────────────────────────────────────────────────┘
```

---

### 6. RAG 完整工作流程

```
┌──────────────────────────────────────────────────────────────────┐
│                        RAG 检索增强生成流程                        │
└──────────────────────────────────────────────────────────────────┘

用户提问: "什么是机器学习？"
         ↓
┌────────────────────────────┐
│ 1. 查询向量化（可选）      │
│    embedding_service.       │
│    embed("什么是机器学习")  │
│    → [0.1, 0.2, 0.3, ...]  │
└────────────────────────────┘
         ↓
┌────────────────────────────────────────┐
│ 2. 在 data/rag-index 中检索  ⭐        │
│    ragService.searchByText(            │
│        "什么是机器学习", 5)            │
│         ↓                              │
│    【查询倒排索引】                    │
│    读取 _35_Lucene99_0.doc             │
│         ↓                              │
│    找到相关文档:                       │
│      - doc-001 (分数: 8.5)            │
│      - doc-042 (分数: 7.2)            │
│      - doc-005 (分数: 6.1)            │
│      - doc-078 (分数: 5.8)            │
│      - doc-103 (分数: 5.2)            │
│         ↓                              │
│    【读取文档内容】                    │
│    读取 _35.fdt                        │
└────────────────────────────────────────┘
         ↓
┌────────────────────────────────────────┐
│ 3. 提取 TOP-K 文档内容                 │
│    context = [                         │
│      "doc-001: 机器学习是...",        │
│      "doc-042: 监督学习包括...",      │
│      "doc-005: 深度学习是..."         │
│    ]                                   │
└────────────────────────────────────────┘
         ↓
┌────────────────────────────────────────┐
│ 4. 构建 LLM Prompt                     │
│    prompt = """                        │
│    基于以下上下文回答问题:              │
│                                        │
│    上下文:                             │
│    doc-001: 机器学习是...             │
│    doc-042: 监督学习包括...           │
│    doc-005: 深度学习是...             │
│                                        │
│    问题: 什么是机器学习？              │
│    """                                 │
└────────────────────────────────────────┘
         ↓
┌────────────────────────────────────────┐
│ 5. 调用 LLM 生成答案                   │
│    aiService.chat(prompt)              │
│         ↓                              │
│    回答: "机器学习是人工智能的一个     │
│           分支，它通过算法让计算机     │
│           从数据中学习规律..."         │
└────────────────────────────────────────┘
         ↓
    返回给用户 ✅
```

---

## 📊 文件大小和性能指标

### 典型索引大小

```
文档数量: 1000个
平均文档大小: 2KB
索引目录大小: ~15MB

文件分布:
├─ 倒排索引文件: ~8MB  (54%)
│   └─ .doc, .pos, .tim, .tip
├─ 存储文件: ~5MB      (33%)
│   └─ .fdt, .fdx
├─ 元数据文件: ~2MB    (13%)
│   └─ .si, .fnm, .nvm, .nvd
└─ 段元数据: ~10KB     (<1%)
    └─ segments_*, write.lock
```

### 性能指标

```
操作             |  性能       |  说明
-----------------+-------------+-------------------------
索引单个文档     |  ~5ms       |  包括分词和写入
批量索引100个    |  ~300ms     |  平均每个3ms
文本搜索         |  ~2ms       |  返回TOP-10
向量搜索         |  ~10ms      |  暴力计算相似度
段合并          |  后台异步    |  不影响查询
重建索引(1000个) |  ~5秒       |  清空后重新索引
```

---

生成时间: 2025-12-24
作者: AI Assistant
状态: ✅ 完整流程图

