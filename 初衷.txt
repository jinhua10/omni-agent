之所以做omni-agent的原因是，现如今的RAG存在着严重的设计缺陷。
如果你只是想做一个聊天机器人，那么目前的RAG是够用的，但如果你想让AI帮你干活，作为生产工具，那么当下普遍的架构：
数据->分块->向量化->向量数据库存储->RAG完成。
然后用户提问->提炼用户问题->问题转换为语义向量->向量数据库检索->返回对应的块拼接到上下文->调用大模型生成回答。
那么可能造成的结果，你认为AI在帮你干活，但实际上AI只是在做文本补全，在一本正经的胡说八道，不能保证准确性。
可以肯定的是目前市面上的通用大模型都很强大，相当于孩子IQ很高，但是专业知识缺乏，运用到工作时会遇到各种水土不服。
也同样可以确定的是AI能够帮你干活,我们已经看到了Cursor、Copilot等工具的出现，并且真实的在工作中发挥了作用。
但这些前提是你喂给AI的内容不丢信息，内容完整，并且你清楚你的需求，并且描述的清楚，那么AI可以基于你给的信息利用它的推理能力帮你干活。
可以把大语言模型比作一堆带有概率的数据，如果你描述问题清晰，那么当你把这个问题喂给AI后，实际上和你的RAG系统差不多的原理，
它只不过是在一堆数据中检索和你问题最相关的内容，然后基于这些内容进行推理，给你一个答案。
说到这里，你也应该明白了一点，你使用的AI模型也只是基于现阶段人类所有遇到的问题和解决方案做的一个概率统计模型，也因此目前的AI模型各有专长，
源于它们训练的模型，训练的方向并不同，因此这只是一个概率问题。
到这里，你应该明白了，没有大数据的支持以及训练，现阶段的AI应用生成的答案可靠性是一个大大的问好？
故，我要做omni-agent！！！就是为了解决这个问题，当然我的方案并非完美，或许你有更好的方案、我很乐意学习。
当然这里还需要解决一个问题，AI模型的上下文窗口不是无限的，这个也是需要解决的。假如说你有个大上下文窗口的AI模型，例如有100W Token的上下文窗口，
真正使用的时候，你还是会遇到“答非所问”等问题，你喂的内容越多，进行检索时离你的答案越偏离

